# -*- coding: utf-8 -*-
"""Sentiment Analysis Supervised_Methods.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XrnxwWUTZ37IPdRTFu3447O5layQ2YI1

## 1. Load and Analyze Dataset

* Initiate the connection with Google Drive
"""

# Import PyDrive2 and associated libraries
from pydrive2.auth import GoogleAuth
from pydrive2.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

# Authenticate and create the PyDrive2 client
# This only needs to be done once per notebook
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

"""* Specify the Google Drive file ID


"""

# Download a file based on its file ID.

# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz
file_id = '1EsPXltlynyR-SvoOmi7PM43lVAQcw_tI' # Check your own ID in GDrive
downloaded = drive.CreateFile({'id': file_id})

# Save file in Colab memory
downloaded.GetContentFile('Dataset_V4.csv')

"""* Read Dataframe stored in Google Drive under `.csv` format"""

import pandas as pd
import numpy as np

df = pd.read_csv("Dataset_V4.csv")

"""* Use the `sample` method to look at some random tweets present in our datase"""

df.sample(20)

#Since the data is imported as a string , we would break it in three different columns
df[['tweet_id', 'tweet_text', 'sentiment']] = df['text_id;tweet_text;sentiment'].str.split(pat=';', n=2, expand=True)

df = df.drop(columns=['text_id;tweet_text;sentiment'])

df.sample(5)

selected_tweet_id = 37862
selected_tweet = df.iloc[selected_tweet_id]
print("Selected Tweet: {}".format(selected_tweet["tweet_text"]))
print("Sentiment of the selected tweet: {}".format(selected_tweet["sentiment"]))

"""## 2. Data Visualization"""

import matplotlib.pyplot as plt

sentiment_counts = df["sentiment"].value_counts()
categories = sentiment_counts.index
counts = sentiment_counts.values

plt.figure(figsize=(6, 6))
plt.pie(counts, labels=categories, autopct='%1.1f%%', startangle=140)
plt.title("Distribution of Sentiments")
plt.show()

num_positive_tweets = df[df["sentiment"] == "positive"].count()[0]
num_negative_tweets = df[df["sentiment"] == "negative"].count()[0]

print("Count of positive tweets: {}".format(num_positive_tweets))
print("Count of negative tweets: {}".format(num_negative_tweets))

pip install wordcloud

from wordcloud import WordCloud

positive_tweets = df[df["sentiment"] == "positive"]
text_combined = "".join(tweet.lower() for tweet in positive_tweets["tweet_text"])
wordcloud = WordCloud().generate(text_combined)

plt.imshow(wordcloud, interpolation="bilinear")
plt.axis("off")
plt.show()

negative_tweets = df[df["sentiment"] == "negative"]
text_combined = "".join(tweet.lower() for tweet in negative_tweets["tweet_text"])
wordcloud = WordCloud().generate(text_combined)

plt.imshow(wordcloud, interpolation="bilinear")
plt.axis("off")
plt.show()

"""## 3. Text Normalization"""

import regex as re

tweet = "today is our two month anniversary!!! i love you sooooooo much Diana. omg you dont even know http://tinyurl.com/dcuc33  #LOVE @meetthepress @SenJohnMcCain @newtgingrich @davidgregory"

"""### <img src='https://drive.google.com/uc?export=view&id=1aAdtCrMe6SORoGAGtjOVM0UIxDFH9Thq' width=50px>  REPLACE USER"""

def replace_user(tweet, default_replace="tweetuser"):
  tweet = re.sub('\B@\w+', default_replace, tweet)
  return tweet

print("Processed tweet: {}".format(replace_user(tweet)))

"""### <img src='https://drive.google.com/uc?export=view&id=1aAdtCrMe6SORoGAGtjOVM0UIxDFH9Thq' width=50px>  REPLACE URL"""

def replace_url(tweet, default_replace=""):
  tweet = re.sub('(http|https):\/\/\S+', default_replace, tweet)
  return tweet

print("Processed tweet: {}".format(replace_url(tweet)))

"""

```
# This is formatted as code
```

### <img src='https://drive.google.com/uc?export=view&id=1aAdtCrMe6SORoGAGtjOVM0UIxDFH9Thq' width=50px>  REMOVE Hashtag"""

def replace_hashtag(tweet, default_replace=""):
  tweet = re.sub('#+', default_replace, tweet)

  return tweet

print("Processed tweet: {}".format(replace_hashtag(tweet)))

"""
```
# This is formatted as code
```

### <img src='https://drive.google.com/uc?export=view&id=1aAdtCrMe6SORoGAGtjOVM0UIxDFH9Thq' width=50px>  REMOVE Upper  Capitalization
"""

def to_lowercase(tweet):
  tweet = tweet.lower()
  return tweet

print("Processed tweet: {}".format(to_lowercase(tweet)))

"""
```
# This is formatted as code
```

### <img src='https://drive.google.com/uc?export=view&id=1aAdtCrMe6SORoGAGtjOVM0UIxDFH9Thq' width=50px>  REMOVE Word Repition"""

def word_repetition(tweet):
  tweet = re.sub(r'(.)\1+', r'\1\1', tweet)
  return tweet

print("Processed tweet: {}".format(word_repetition(tweet)))

"""
```
# This is formatted as code
```

### <img src='https://drive.google.com/uc?export=view&id=1aAdtCrMe6SORoGAGtjOVM0UIxDFH9Thq' width=50px>  Punctuation Repition"""

def punct_repetition(tweet, default_replace=""):
  tweet = re.sub(r'[\?\.\!]+(?=[\?\.\!])', default_replace, tweet)
  return tweet

print("Processed tweet: {}".format(punct_repetition(tweet)))

pip install contractions

"""
```
# This is formatted as code
```

### <img src='https://drive.google.com/uc?export=view&id=1aAdtCrMe6SORoGAGtjOVM0UIxDFH9Thq' width=50px>  Word Contraction"""

import contractions

print(contractions.contractions_dict)

def fix_contractions(tweet):
  tweet = contractions.fix(tweet)
  return tweet

print("Processed tweet: {}".format(fix_contractions(tweet)))

"""## 4. Text Tokenization"""

pip install nltk

import nltk
from nltk.tokenize import word_tokenize
nltk.download('punkt')

tweet = "These are 5 different words!"

def tokenize(tweet):
  tokens = word_tokenize(tweet)
  return tokens

print(type(tokenize(tweet)))
print("Tweet tokens: {}".format(tokenize(tweet)))

import string

print(string.punctuation)

from nltk.corpus import stopwords
nltk.download('stopwords')

stop_words = set(stopwords.words('english'))
print(stop_words)

stop_words.discard('not')
stop_words.discard('no')
print(stop_words)

def custom_tokenize(tweet,
                    keep_punct=False,
                    keep_alnum=False,
                    keep_stop=False):

  token_list = word_tokenize(tweet)

  if not keep_punct:
    token_list = [token for token in token_list
                  if token not in string.punctuation]

  if not keep_alnum:
    token_list = [token for token in token_list if token.isalpha()]

  if not keep_stop:
    stop_words = set(stopwords.words('english'))
    stop_words.discard('not')
    token_list = [token for token in token_list if not token in stop_words]

  return token_list

tweet = "these are 5 different words!"

print("Tweet tokens: {}".format(custom_tokenize(tweet,
                                                keep_punct=True,
                                                keep_alnum=True,
                                                keep_stop=True)))
print("Tweet tokens: {}".format(custom_tokenize(tweet, keep_stop=True)))
print("Tweet tokens: {}".format(custom_tokenize(tweet, keep_alnum=True)))
print("Tweet tokens: {}".format(custom_tokenize(tweet, keep_alnum=False, keep_stop=False)))

"""## 5. Text Stemming"""

from nltk.stem import PorterStemmer
from nltk.stem import LancasterStemmer
from nltk.stem.snowball import SnowballStemmer

tokens = ["manager", "management", "managing"]

porter_stemmer = PorterStemmer()
lancaster_stemmer = LancasterStemmer()
snoball_stemmer = SnowballStemmer('english')

def stem_tokens(tokens, stemmer):
  token_list = []
  for token in tokens:
    token_list.append(stemmer.stem(token))
  return token_list

print("Porter stems: {}".format(stem_tokens(tokens, porter_stemmer)))
print("Lancaster stems: {}".format(stem_tokens(tokens, lancaster_stemmer)))
print("Snowball stems: {}".format(stem_tokens(tokens, snoball_stemmer)))

complex_tweet = r"""RT @AIOutsider : he looooook,
THis is a big and complex TWeet!!! üëç ...
We'd be glad if you couldn't normalize it!
Check https://t.co/7777 and LET ME KNOW!!! #NLP #Fun"""

"""## 6. Putting All together"""

def process_tweet(tweet, verbose=False):
  if verbose: print("Initial tweet: {}".format(tweet))

  ## Twitter Features
  tweet = replace_user(tweet, "") # replace user tag
  tweet = replace_url(tweet)    # replace url
  tweet = replace_hashtag(tweet) # replace hashtag
  if verbose: print("Post Twitter processing tweet: {}".format(tweet))

  ## Word Features
  tweet = to_lowercase(tweet) # lower case
  tweet = fix_contractions(tweet) # replace contractions
  tweet = punct_repetition(tweet) # replace punctuation repetition
  tweet = word_repetition(tweet)# replace word repetition
  if verbose: print("Post Word processing tweet: {}".format(tweet))

  ## Tokenization & Stemming
  tokens = custom_tokenize(tweet, keep_alnum=False, keep_stop=False) # tokenize
  stemmer = SnowballStemmer("english") # define stemmer
  stem = stem_tokens(tokens, stemmer)# stem tokens

  return stem

print(process_tweet(complex_tweet, verbose=False))

import random

for i in range(5):
  tweet_id = random.randint(0,len(df))
  tweet = df.iloc[tweet_id]["tweet_text"]
  print(process_tweet(tweet, verbose=True))
  print("\n")

"""## 7. Tweet Processing"""

pip install scikit-learn

df["tokens"] = df["tweet_text"].apply(process_tweet)

df["tweet_sentiment"] = df["sentiment"].apply(lambda i : 1
                                              if i == "positive" else 0)
df.head(10)

X = df["tokens"].tolist()
y = df["tweet_sentiment"].tolist()

print(df.head())

pip install gensim nltk

import pandas as pd

# 'y' is  target variable containing class labels
class_distribution = pd.Series(y).value_counts()
print("Class distribution:\n", class_distribution)

# For a percentage view
class_distribution_percentage = pd.Series(y).value_counts(normalize=True) * 100
print("\nClass distribution (percentage):\n", class_distribution_percentage)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y,
                                                    random_state=0,
                                                    train_size = 0.80)

print("Size of X_train: {}".format(len(X_train)))
print("Size of y_train: {}".format(len(y_train)))
print("\n")
print("Size of X_test: {}".format(len(X_test)))
print("Size of y_test: {}".format(len(y_test)))
print("\n")
print("Train proportion: {:.0%}".format(len(X_train)/
                                        (len(X_train)+len(X_test))))

"""## Multinomial Naive Bayes Implementation"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import precision_recall_curve, roc_curve, auc, roc_auc_score, confusion_matrix
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn import metrics
import time

# Function to train and evaluate Multinomial Naive Bayes model
def train_evaluate_multinomial_nb(X_train, y_train, X_test, y_test, vectorizer_type, plot_charts=False):
    start_time = time.time()

    # Choose the vectorizer
    if vectorizer_type == 'tfidf':
        vectorizer = TfidfVectorizer(preprocessor=lambda x: ' '.join(x))
        label = 'TF-IDF'
    elif vectorizer_type == 'bow':
        vectorizer = CountVectorizer(preprocessor=lambda x: ' '.join(x))
        label = 'Bag of Words'

    # Transform data
    X_train_transformed = vectorizer.fit_transform(X_train)
    X_test_transformed = vectorizer.transform(X_test)

    # Initialize and train model
    nb_model = MultinomialNB()
    nb_model.fit(X_train_transformed, y_train)

    # Predictions
    y_pred = nb_model.predict(X_test_transformed)
    y_proba = nb_model.predict_proba(X_test_transformed)[:, 1]

    # End time measurement
    end_time = time.time()
    duration = end_time - start_time

    # Performance metrics
    accuracy = metrics.accuracy_score(y_test, y_pred)
    precision_metric = metrics.precision_score(y_test, y_pred)
    recall_metric = metrics.recall_score(y_test, y_pred)
    f1 = metrics.f1_score(y_test, y_pred)
    roc_auc = roc_auc_score(y_test, y_proba)

    # Print metrics
    print(f"Vectorizer Type: {vectorizer_type} ({label})")
    print(f"Accuracy: {accuracy:.4f}")
    print(f"Precision: {precision_metric:.4f}")
    print(f"Recall: {recall_metric:.4f}")
    print(f"F1 Score: {f1:.4f}")
    print(f"AUC-ROC Score: {roc_auc:.4f}")
    print(f"Training and Prediction Time: {duration:.4f} seconds")

    # Plotting charts
    if plot_charts:
        plt.figure(figsize=(6, 4))  # Reduced size
        cm = confusion_matrix(y_test, y_pred)
        sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False, xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])
        plt.title(f'Confusion Matrix - {label}')
        plt.xlabel('Predicted')
        plt.ylabel('True')
        plt.show()

        plt.figure(figsize=(6, 4))  # Reduced size
        fpr, tpr, _ = roc_curve(y_test, y_proba)
        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f}) - {label}')
        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
        plt.xlabel('False Positive Rate')
        plt.ylabel('True Positive Rate')
        plt.title(f'Receiver Operating Characteristic - {label}')
        plt.legend(loc="lower right")
        plt.show()

        if len(y_proba) > 0 and len(np.unique(y_test)) > 1:
            plt.figure(figsize=(6, 4))  # Reduced size
            precision, recall, _ = precision_recall_curve(y_test, y_proba)
            pr_auc = auc(recall, precision)
            plt.plot(recall, precision, color='green', lw=2, label=f'Precision-Recall curve (area = {pr_auc:.2f}) - {label}')
            plt.fill_between(recall, precision, alpha=0.2, color='green')
            plt.xlabel('Recall')
            plt.ylabel('Precision')
            plt.title(f'Precision-Recall Curve - {label}')
            plt.legend(loc="lower left")
            plt.show()
        else:
            print("Not enough data to plot Precision-Recall curve.")

    return nb_model, vectorizer, y_pred, y_proba, duration

# Example usage
nb_model_tfidf, vectorizer_tfidf, y_pred_tfidf, y_proba_tfidf, duration_tfidf = train_evaluate_multinomial_nb(
    X_train, y_train, X_test, y_test, 'tfidf', plot_charts=True)

nb_model_bow, vectorizer_bow, y_pred_bow, y_proba_bow, duration_bow = train_evaluate_multinomial_nb(
    X_train, y_train, X_test, y_test, 'bow', plot_charts=True)

# Function to show top features for each class
def show_top10(classifier, vectorizer, class_labels):
    feature_names = np.array(vectorizer.get_feature_names_out())
    for i, class_label in enumerate(class_labels):
        top10 = classifier.feature_log_prob_[i].argsort()[-10:]
        print(f"Class {class_label}: {' '.join(feature_names[top10])}")

# Show top features for TF-IDF
print("Top features for TF-IDF:")
show_top10(nb_model_tfidf, vectorizer_tfidf, nb_model_tfidf.classes_)

# Show top features for BoW
print("\nTop features for BoW:")
show_top10(nb_model_bow, vectorizer_bow, nb_model_bow.classes_)

from sklearn.model_selection import learning_curve

def plot_learning_curve(model, X, y, title):
    train_sizes, train_scores, test_scores = learning_curve(
        model, X, y, cv=5, scoring='accuracy', n_jobs=-1, train_sizes=np.linspace(0.01, 1.0, 50))

    train_mean = np.mean(train_scores, axis=1)
    train_std = np.std(train_scores, axis=1)
    test_mean = np.mean(test_scores, axis=1)
    test_std = np.std(test_scores, axis=1)

    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color="r", alpha=0.1)
    plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color="g", alpha=0.1)
    plt.plot(train_sizes, train_mean, 'o-', color="r", label="Training score")
    plt.plot(train_sizes, test_mean, 'o-', color="g", label="Cross-validation score")

    plt.title(title)
    plt.xlabel("Training Set Size"), plt.ylabel("Accuracy Score"), plt.legend(loc="best")
    plt.show()

# Plot learning curve for TF-IDF
plot_learning_curve(nb_model_tfidf, vectorizer_tfidf.transform(X_train), y_train, "Learning Curve (TF-IDF)")

# Plot learning curve for BoW
plot_learning_curve(nb_model_bow, vectorizer_bow.transform(X_train), y_train, "Learning Curve (BoW)")

# Create a DataFrame for analysis using X_test and y_test
df_test = pd.DataFrame({'actual': y_test, 'predicted_tfidf': y_pred_tfidf, 'predicted_bow': y_pred_bow})

# Analyze misclassified examples for TF-IDF
misclassified_tfidf = df_test[df_test['actual'] != df_test['predicted_tfidf']]
print("Misclassified samples for TF-IDF:")
print(misclassified_tfidf.sample(10))

# Analyze misclassified examples for BoW
misclassified_bow = df_test[df_test['actual'] != df_test['predicted_bow']]
print("\nMisclassified samples for BoW:")
print(misclassified_bow.sample(10))

"""## Support Vector Machine Implementation"""

from sklearn.svm import SVC
from sklearn.metrics import precision_recall_curve, roc_curve, auc, roc_auc_score, confusion_matrix
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn import metrics
import matplotlib.pyplot as plt
import seaborn as sns
import time

# Function to train and evaluate SVM model with visuals
def train_evaluate_svm_with_visuals(X_train, y_train, X_test, y_test, vectorizer_type):
    start_time = time.time()

    # Choose the vectorizer
    if vectorizer_type == 'tfidf':
        vectorizer = TfidfVectorizer(preprocessor=lambda x: ' '.join(x))
        label = 'TF-IDF'
    elif vectorizer_type == 'bow':
        vectorizer = CountVectorizer(preprocessor=lambda x: ' '.join(x))
        label = 'Bag of Words'

    # Transform data
    X_train_transformed = vectorizer.fit_transform(X_train)
    X_test_transformed = vectorizer.transform(X_test)

    # Initialize and train model
    svm_model = SVC(kernel='linear', probability=True)
    svm_model.fit(X_train_transformed, y_train)

    # Predictions
    y_pred = svm_model.predict(X_test_transformed)
    y_proba = svm_model.predict_proba(X_test_transformed)[:, 1]

    # End time measurement
    end_time = time.time()
    duration = end_time - start_time

    # Performance metrics
    accuracy = metrics.accuracy_score(y_test, y_pred)
    precision_metric = metrics.precision_score(y_test, y_pred)
    recall_metric = metrics.recall_score(y_test, y_pred)
    f1 = metrics.f1_score(y_test, y_pred)
    roc_auc = roc_auc_score(y_test, y_proba)

    # Print metrics and duration
    print(f"Vectorizer Type: {vectorizer_type} ({label})")
    print(f"Accuracy: {accuracy:.4f}")
    print(f"Precision: {precision_metric:.4f}")
    print(f"Recall: {recall_metric:.4f}")
    print(f"F1 Score: {f1:.4f}")
    print(f"AUC-ROC Score: {roc_auc:.4f}")
    print(f"Training and Prediction Time: {duration:.4f} seconds")

    # Plot the confusion matrix
    plt.figure(figsize=(6, 4))
    cm = confusion_matrix(y_test, y_pred)
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False,
                xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])
    plt.title(f'Confusion Matrix - {label}')
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.show()

    # Plot the ROC curve
    plt.figure(figsize=(6, 4))
    fpr, tpr, _ = roc_curve(y_test, y_proba)
    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f}) - {label}')
    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title(f'Receiver Operating Characteristic - {label}')
    plt.legend(loc="lower right")
    plt.show()

    # Precision-Recall curve
    if len(y_proba) > 0 and len(np.unique(y_test)) > 1:
        plt.figure(figsize=(6, 4))
        precision, recall, _ = precision_recall_curve(y_test, y_proba)
        pr_auc = auc(recall, precision)
        plt.plot(recall, precision, color='green', lw=2, label=f'Precision-Recall curve (area = {pr_auc:.2f}) - {label}')
        plt.fill_between(recall, precision, alpha=0.2, color='green')
        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title(f'Precision-Recall Curve - {label}')
        plt.legend(loc="lower left")
        plt.show()
    else:
        print("Not enough data to plot Precision-Recall curve.")

    return svm_model, vectorizer, y_pred, y_proba, duration

# Example usage
svm_model_tfidf, vectorizer_tfidf, y_pred_tfidf_svm, y_proba_tfidf_svm, duration_tfidf_svm = train_evaluate_svm_with_visuals(
    X_train, y_train, X_test, y_test, 'tfidf')

svm_model_bow, vectorizer_bow, y_pred_bow_svm, y_proba_bow_svm, duration_bow_svm = train_evaluate_svm_with_visuals(
    X_train, y_train, X_test, y_test, 'bow')